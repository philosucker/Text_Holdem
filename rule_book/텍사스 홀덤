헤드업 무제한 텍사스 홀덤

Heads-up No-limit Texas Hold'em

1.
개인 참여자들에게는 각각 2장의 카드(포켓카드)가 주어진다
프리플롭 pre-flop 베팅
이때 콜, 레이즈를 할 수 있다
순서는 기준 베팅 금액(빅블라인드)를 가지지 않는 플레이어들로부터 시작?

2.
첫번째 베팅이 끝나면 
딜러가 3장의 카드 앞면을 가운데 놓고 (커뮤니티 카드) 두번째 베팅을 시작한다
플롭 flop 베팅

3.
다음으로 한장의 카드앞면을 추가로 공개하고 베팅한다
턴 turn 카드 베팅

4.
마지막으로 한장의 카드 앞면을 추가로 공개하고 베팅한다.
리버 카드
마지막 베팅


이렇게 공개된 5장의 카드와 
자신이 가진 2장의 카드를 조합해
가장 좋은 패를 가진 사람이 승리한다

베팅, 빅블라인드, 싱글블라인드, 레이즈, 콜, 폴드, 첵, 블러핑





불완전 정보게임에서는
거의 마지막 순간에 나에게 에이스가 4개 있다 하더라도 공격적으로 베팅할 수 없다
동시에 내 패가 약하다고 베팅까지 약하게 하면 안된다. 그러면 상대방에게 간파당한다.

정보가 불완전한 상태에서, 허위정보가 껴있는 상황에서 의사결정을 해야 하는 상황

카네기 멜론 토마스 샌드홀름, 노암 브라운 : 클라우디코 claudico 2015년

타르타니안 tartanian 2016년

리브라투스 libratus 2017년 (슈퍼컴 사용. 강화학습 알고리즘. 사전학습을 하지 않고 실전 경기에서 오는 정보만으로 대결
1:1
	샌드홀름 교수는 "매일 경기가 끝난 뒤 리브라투스에 탑재된 메타알고리즘이 상대방 선수들이 어떤 취약점을 확인해서 활용했는지 분석한다"고 설명했다.

	그 다음으로는 "매일 밤 슈퍼컴퓨터를 활용해 선수들이 사용한 취약점들에 우선 순위를 매긴 뒤 이들 중 톱3를 선정해 알고리즘에 패치를 한다"고 덧붙였다.

	"일반적으로 연구원들이 상대방의 취약점을 공략할 수 있는 알고리즘을 개발하는 반면 우리는 우리의 전략 중 취약한 부분을 알고리즘적으로 수정해 매일 개선해나갔다"는 설명이다.
	
	
딥스택 deepstack 2017 캐나다 앨버타대(마이클 볼링 교수), 체코 프라하 카릴대, 체코 공과대 
1:1

	포커 규칙은 포커 대회에서 가장 널리 쓰이는 '헤즈업 무제한 텍사스 홀덤'(Heads-Up No-Limit Texas Hold'em·HUNL)을 사용했으며, 칩은 게임당 2만개, 게임 중 기준 베팅 금액(빅 블라인드·big blind)은 칩 100개였다. 플레이어는 각 게임에서 전체 칩 갯수 범위 내에서 무제한으로 베팅을 할 수 있었다.

	반복되는 포커 게임에서 거둔 플레이어의 성적은 이 분야 연구자들의 관행에 따라 'mbb/g'(milli-big-blind per game)로 따졌다. 이는 플레이어가 평균적으로 게임당 따는 돈이 빅 블라인드의 몇 배인지 천분율로 계산한 것이다. 포커는 확률 게임이므로 개별 게임의 결과로만 플레이어의 역량을 가늠할 수 없으며, 매우 많은 횟수의 게임을 했을 때 얼마나 많은 돈을 따느냐를 봐야 한다.

	처음에 항상 포기하는 플레이어는 750 mbb/g 차로 지게 되어 있으며, 프로 도박사들은 대개 고객을 상대로 50 mbb/g 차이로 돈을 따는 것을 최소 목표로 삼는다. 2015년에는 당시 최고로 꼽히던 포커 컴퓨터 프로그램 '클라우디코'가 인간 프로 도박사 팀에 91mbb/g의 '상당한 격차'로 패배한 적이 있다.


게임인원수가 많으면 스트레이트, 플러시, 풀 하우스등이 더 높게 발생할 가능성이 높기 때문에 페어로 승리로 하는 것이 더 힘들다.

플루리버스 2019 토마스 샌드홀름 카네기 멜론
1:5
연구진은 플루리버스가 상대가 경기 끝까지 어떻게 플레이하는지 장기 예측을 하려고 하기보다는 2~3라운드 까지만 예측해 다양한 상황에 즉각 대처하도록 했다.


ReBel 2020 페이스북  

강화학습+검색 특정 행동이 선택될 확률에 관계없이 각 행동에 고정 값을 할당해 계산해 버리는 경향이 있다. 체스 같은 게임에서는 플레이어가 자주 사용하는 손인지 아닌지에 관계없이 묘수는 묘수, 악수는 악수이기 때문에, 이런 문제는 그다지 표면화하지 않는다. 하지만 포커에서는 ‘허세’를 자주 사용하면 ‘허세’가 읽히듯이 특정 행도의 가치는 사용 빈도에 따라 변동이 생기기 때문에 행동이 선택되는 확률이 매우 중요하다.

그래서 페이스북이 이번에 발표한 AI ReBeL는 각 플레이어가 가질 수 있는 다양한 ‘신념 (belief)’의 확률 분포를 계산해 행동을 결정하도록 했다.

즉, 각 플레이어의 신념을 설명함으로써, ReBeL은 완벽한 정보 게임과 같은 불완전한 정보 게임을 다룰 수 있다. 그러면 ReBeL은 불완전한 정보 게임의 더 복잡한 (고차원) 상태와 액션 공간을 다루기 위해 RL+Search 알고리즘을 활용할 수 있다.



피오솔버
https://www.donga.com/news/Inter/article/all/20220119/111318563/1
https://xn--vg1b002a0hjg5e.com/%ED%8F%AC%EC%BB%A4-%EB%89%B4%EC%8A%A4/%ED%8F%AC%EC%BB%A4%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/


