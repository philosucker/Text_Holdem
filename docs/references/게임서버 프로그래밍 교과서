2장 컴퓨터 네트워크



LAN이 성립하려면 OSI 모델의 layer 2 (데이터 링크 계층) 표준 만 지켜주면 된다.
OSI (Open Systems Interconnetion reference) 

layer 1 물리계층
데이터를 어떤 파형의 전류로 보낼 것인지 정의

layer2 데이터 링크 계층
LAN (Local Area Network) 통신이 가능하게 한다
LAN : 모든 단말기들이 하나의 스위치에 랜선으로 연결된 네트워크 = star topology

    헤더 : MAC 주소(단말기의 고유한 주소) 등을 정의
    페이로드 : 보내고자 하는 데이터
    프레임 = 헤더 + 페이로드
    좀 더 정확히는 프레임 = 데이터 링크 헤더 + (IP 헤더 + (TCP 헤더 + 페이로드) + 트레일러 ) 식으로 되어 있다.

layer3 네트워크 계층
WAN(Wide Area Network) 통신이 가능하게 한다.
WAN : 모든 스위치들을 라우터에 연결한 네트워크
인터넷 : 라우터들끼리도 연결한 네트워크

IPv4, IPv6 (Intenet Protocol) OSI 모델 계층 3의 인터넷 프로토콜을 지키면 기기 종류와 상관 없이 서로 통신할 수 있다
통신 회선의 형태가 랜선이든, 광섬유 ,무선 어떤 것이든 상관 없이

인터넷 프로토콜을 지킨다는 것의 의미
    모든 기기는 IP주소를 갖는다. IPv4 또는 IPv6
        IPv4는 가용 주소 숫자가 부족해서 NAT (Network Address Translation) 기술을 쓰는 라우터, 즉 가정용 인터넷 공유기를 쓴다.
            포트매핑, 홀펀칭 >> 포트포워딩과 관련
    기기 내에서 돌아가는 프로세스들에게도 주소를 매기기 위해 포트번호를 쓴다
    end point = IP주소 + 포트번호
    도메인 이름 서버 (DNS server) : ip주소와 맵핑 되어 있는 영문자 주소를 host name 호스트 이름 이라고 하고, 이 호스트 이름을 IP 주소로 변환해주는 서버가 DNS 서버다. 우리가 www.naver.com 을 입력하면 운영체제는 호스트 이름을 DNS 서버에 물어서 해당 호스트이름의 IP 주소를 알려준다.
    소스 IP 주소, 목적지 IP 주소는 IP 헤더에 들어가고 IP헤더는 layer4에서 만들어진 세그먼트 앞에 붙는다.

layer4 전송 계층
이 계층에서는 데이터가 반드시 도착하게 한다 (TCP/IP)

소스포트, 목적지 포트번호는 TCP헤더 또는 UDP 헤더에 들어가고 이 헤더는 데이터가 쪼개진 세그먼트들 앞에 붙는다.

layer 5, 6, 7 응용계층
동영상 스트리밍 통신 규약 MPEG, 통신 암호화 규약(SSL), 웹 브라우저와 웹 서버간 통신 규약 (HTTP) 등을 정의

계층별 데이터 흐름
    응용 계층 (Application Layer): 
    사용자가 보내고자 하는 데이터를 생성합니다. 예를 들어, 이메일 메시지나 웹 페이지 요청.

    전송 계층 (Transport Layer): 
    응용 계층 데이터를 세그먼트(segment)나 데이터그램(datagram)으로 나눕니다. 이 계층에서는 TCP나 UDP 프로토콜을 사용합니다.

    네트워크 계층 (Network Layer): 
    전송 계층 데이터를 패킷(packet)으로 캡슐화합니다. IP 주소를 포함하여 데이터를 목적지까지 라우팅합니다.

    데이터 링크 계층 (Data Link Layer): 
    네트워크 계층의 패킷을 프레임(frame)으로 캡슐화합니다. 이 계층은 MAC 주소를 사용하여 동일 네트워크 내에서 데이터를 전송합니다.

    물리 계층 (Physical Layer): 
    데이터 링크 계층의 프레임을 실제 전기 신호나 광 신호로 변환하여 물리적 매체를 통해 전송합니다.

데이터를 컴퓨터A에서 컴퓨터B로 전송할때
A는 데이터를 세그먼트들로 자르고 TCP 또는 UDP헤더를 붙인다 : 세그먼트화
각 세그먼트들 각각에 IP 헤더와 트레일러를 붙인다 : 패킷화
    일정 크기 : 네트워크의 최대 전송 단위(MTU, Maximum Transmission Unit)
    이렇게 만든 패킷들은 600바이트에서 9000 바이트까지 다양한데 대개 1300바이트 정도다.

일반적인 캡슐화 과정:
패킷을 쪼개지 않고, IP 패킷 전체를 데이터 링크 계층의 프레임으로 캡슐화합니다. 프레임화

fragmentation : 
패킷이 MTU를 초과하는 경우 패킷을 MTU 단위로 쪼개서 각각에 데이터링크 헤더와 트레일러를 붙여 프레임들을 만든다 : 프레임화 
프래그멘테이션은 컴퓨터나 라우터가 할 수 있다.

데이터 전송 과정
    송신자에서 스위치로:
    송신자의 컴퓨터에서 생성된 프레임은 물리계층에서 신호로 변환되어 스위치로 전달됩니다.
    스위치는 프레임의 데이터 링크 헤더(MAC 주소)를 보고 동일 네트워크 내의 적절한 포트로 프레임을 전달합니다.
        데이터 링크 헤더의 MAC 주소는 최종 도착지의 MAC 주소가 아니라, 다음 홉(Next Hop) 장치의 MAC 주소를 포함합니다. 
        
    스위치에서 라우터로:
    스위치에서 라우터로 전달될 때, 라우터는 프레임을 수신하여 데이터 링크 계층 헤더를 제거하고, IP 헤더를 확인합니다.
    라우터는 IP 헤더의 목적지 IP 주소를 기반으로 다음 홉(next hop) 라우터를 결정하고, 새로운 데이터 링크 계층 헤더를 추가하여 패킷을 다음 라우터로 전달합니다.
        라우팅 테이블: 목적지 IP 주소를 기반으로 다음 홉 라우터를 결정하는 데 사용됩니다.
            라우팅 테이블에는 다음과 같은 정보가 포함됩니다:
                목적지 네트워크 주소: 라우터가 접근할 수 있는 네트워크들의 IP 주소 범위.
                서브넷 마스크: 네트워크 주소를 결정하는 데 사용되는 마스크.
                게이트웨이 주소 (Next Hop IP 주소): 다음 라우터나 목적지 네트워크로 패킷을 전달하기 위한 IP 주소.
                인터페이스: 패킷을 해당 목적지로 보내기 위해 사용하는 라우터의 네트워크 인터페이스.
                라우팅 테이블은 IP 주소 기반으로 작동하며, MAC 주소 정보를 포함하지 않습니다.
    중간 라우터들:
    중간 라우터들은 동일한 방식으로 작동합니다. 패킷을 수신하면 데이터 링크 계층 헤더를 제거하고, IP 헤더를 확인한 후, 새로운 데이터 링크 계층 헤더를 추가하여 다음 홉 라우터로 패킷을 전달합니다.
    이 과정은 패킷이 최종 목적지 네트워크에 도달할 때까지 반복됩니다.

    최종 목적지 네트워크의 라우터에서 스위치로:
    최종 목적지 네트워크에 도달한 패킷은 해당 네트워크의 라우터에 의해 수신됩니다.
    라우터는 패킷을 수신하여 데이터 링크 계층 헤더를 제거하고, IP 헤더를 확인한 후, 목적지 네트워크 내의 스위치로 패킷을 전달합니다.


    스위치에서 최종 수신자로:
    최종 목적지 네트워크의 스위치는 패킷의 데이터 링크 헤더(MAC 주소)를 확인하여, 최종 수신자의 컴퓨터로 프레임을 전달합니다.
        최종 목적지 네트워크의 라우터는 최종 수신자의 IP 주소를 확인하고, 해당 IP 주소에 대한 MAC 주소를 ARP를 통해 얻습니다.
        최종 수신자의 MAC 주소를 포함하는 새로운 데이터 링크 계층 헤더를 생성하여 패킷을 최종 수신자에게 전달합니다.
        ARP 캐시는 IP 주소와 MAC 주소의 매핑 정보를 저장합니다. 이 테이블은 다음과 같은 정보를 포함합니다:
            IP 주소: 네트워크 상의 장치나 라우터의 IP 주소.
            MAC 주소: 해당 IP 주소에 매핑되는 MAC 주소.
            
이렇게 프레임들이 모여 패킷 하나를 다 조립할 수 있게 되면 패킷 하나를 복원하고, 이렇게 프레임들이 모여서 세그먼트들이 되거나
또는 각각이 패킷인 프레임들이 다 모여서
세그먼트를 조합해서 B는 원래 데이터를 받게 된다.

여기서
라우터마다 성능이 다 다르므로 프레임들을 받아서 어떤 패킷인지 확인하고 다음 라우터로 보낼 때
그 원래 패킷이 너무 큰 경우, 그 패킷을 보내기 위해 너무 많은 프레임이 한 라우터에 올 수도 있고
또는 패킷인 프레임들이 올때, 패킷 자체가 너무 많이 올 수도 있는데
이렇게 라우터가 처리할 수 있는 양 이상의 패킷이 쪼개진 프레임들 또는 패킷들이 몰리면
그 프레임들 또는 패킷을 어디로 보내야 할지 판단하기 위해 내장된 메모리에 액세스하다보면(라우팅 테이블 조회)
그 과정에서 다른 패킷의 프레임들 또는 패킷들이 오기도하고, 이렇게 뒤에 누적된 애들은 처리가 늦어져서 레이턴시가 생길 수 있고
이게 심해져서 버퍼가 가득차 오버플로가 생기면
라우터는 처리량을 넘어선 프레임 또는 패킷들을 그냥 버리기도 해서, 결과적으로 버려지는 패킷이 생길 수 있다.
이를 패킷 드롭이라고 한다.
패킷 유실율은 전송된 총 패킷 수 대비 손실된 패킷의 비율로 계산

또 라우터에 연결된 어느 한곳에 도착하는 패킷이 압도적으로 많으면, 라우터는 그곳에 도착하는 패킷을 처리하느라 다른 곳에서 오는 패킷을 처리 못하고, 다른 곳의 네트워킹 속도가 떨어지게 된다. TCP는 송신쪽에서 초당 보내는 데이터 양이 수신 측에서 초당 수신할 수 있는 데이터 양보다 많을 때
송신자 측 운영체제가 초당 송신량을 자동으로 줄인다. 그래서 라우터에서 네트워크 경쟁이 일어나지 않는다
UDP에는 이런 제어기능이 없다. 따라서 UDP를 속도 제한 없이 마구 송신하면 주변 네트워킹이 두절될 수 있다. 이를 혼잡 현상이라고 한다.

이렇게 라우터 과부하 말고도

최초 무선으로 온 신호가 유선으로 넘어 갈때 노이즈가 섞이거나
신호 자체가 약해지거나 하면 데이터의 내용이 원래와 달라질 수 있는데 이때도 수정이 불가능해 버려지는 프레임이나 패킷이 생길 수 있다. 

패킷은 일반적으로 1300바이트라고 하면 이 정도의 데이터가 버려지는 셈

라디오로 방송을 들을때 지지직 거리는거와 달리 (이 경우는 노이즈가 그대로 같이 와서 들리는 것)
스마트폰으로 라디오를 듣거나 영상을 보면 소리가 늦게 도착하거나, 중간중간 끊어진다. 데이터가 버려지기 때문이다.

전송속도는 두 기기간 초당 전송될수 있는 최대 데이터 양인데 이는 두 기기 사이의 선로의 종류와 품질이 큰 영향을 미친다.

레이턴시(지연시간)은 위에서 말한대로 라우터의 문제도 있고
선로에 훼손이 생겨 신호가 영향을 받을 수도 있다.
이때 신호가 버려지면 보내지는 쪽에서 잠시 뒤 다시 보내기도 하는데 이 것도 레이턴시의 원인이 된다.
    CSMA (Carrier Sense Multiple Access)
        무선 통신에서 데이터를 전자기파로 바꿔 보내기 전에 안테나를 통해 다른 전파가 감지되는지 확인 후
        전파가 감지되지 않으면 전파를 보내고, 감지되면 잠시 기다렸다가 다시 확인후 보낸다.
        신호를 보낸 후 수신자에게서 수신 확인 응답이 안오면, 일정 시간후 다시 신호를 보낸다
라우터에서 패킷이 몰려 라우팅 테이블을 조회하는 일이 늦어지거나, 방화벽에서 연산이 밀리는 경우에도 레이턴시를 증가시킨다.

거치는 라우터 수가 많아도 레이턴시가 늘어난다.

두 단말기 사이의 레이턴시 = 두 단말기 사이에 있는 네트워크 기기의 레이턴시 총합 

따라서 전송속도도
두 단말기 사이의 최대 전송속도 = 두 단말기 사이에 있는 네트워크 기기 중 최소 전송속도가 된다.



따라서 네트워크 품질은
전송속도, 패킷 유실률, 레이턴시 세개로 결정된다.

2.7 패킷 유실시 UDP와 TCP에서 현상

UDP (User Datagram Protocol) 는 64KB 이하 이진 데이터 (데이터그램) 을 메시지로 송수신하는 프로토콜이다. 


    스트림 형식: 보낸 쪽에서 보낸 데이터의 개수와 보낸 데이터의 시작과 끝이, 받는 쪽에서는 달라질 수 있다
        보낸 쪽
            aaa
            bbb
            ccc
        받는 쪽
            a
            aab
            bbcc
            c
    따라서 스트림 형식으로 송수신할 때는 보내는 데이터의 크기를 먼저 보내든가, 데이터의 시작/끝을 알리는 구분자를 보내야 한다

    메시지 형식: 보낸 개수와 받는 개수가 같고, 보낸 데이터와 받는 데이터의 시작과 끝이 같다
        보낸 쪽
            aaa
            bbb
            ccc
        받는 쪽
            aaa
            bbb
            ccc
            
UDP는 메시지 형식이므로 패킷 유실은 생길 수 있으나 데이터 수신에 성공했다면 보낸쪽에서의 데이터와 똑같게 된다.
대신 순서가 뒤바뀔 수 있고, 중복수신될수도 있다.
패킷이 유실되면 그 패킷들로 이뤄진 데이터그램도 최종 유실되는 것이다. 

TCP (Transmission Control Protocol)는 스트림 형식으로 송수신한다. 
수신자는 IP 패킷을 받으면 그 안에서 세그먼트를 꺼내고 송신자에게 응답을 보낸다. 이 응답을 ack라고 한다.
송신측에서는 일정시간안에 세그먼트에 대한 ack가 회신되지 않으면 다시 세그먼트를 보낸다.

TCP는 이 과정때문에 레이턴시가 추가된다.
네트워크 기기의 레이턴시 + (100% - 패킷 유실률) * 재전송 대기 시간

UDP는 레이턴시가 민감하거나 패킷유실이 있어도 되는
음성, 화상, 캐릭터 이동 같은 데이터 전송에 사용한다. 데이터가 유실돼도 뒤따라 오는 데이터에 의해 만회될 수 있으므로

메시지 전송에는 TCP를 쓴다. 꼭 보내져야 하므로.

2.8 주로 사용하는 메시지 형식

게임 메시지는 텍스트 또는 바이너리다.

텍스트는 parser가 필요하다. 

바이너리는 parser가 필요 없어서 빠르고 통신량도 적지만 디버깅이 까다롭다. 읽기 어려우니까 

데이터에 메타데이터를 넣으면 통신량이 많아지고 해킹에도 더 취약해지지만
서로 버전이 다른 두 프로세스에서 통신할때 버전이 높은 쪽이 버전이 낮은쪽에서 주는 부족한 정보를 어느정도 자체 보완할 수 있다.
이를 하위 호완성이 좋다고 한다.
서버는 높은 버전로 업데이트 했는데 클라이언트가 아직 낮은 버전을 써서 서버에 접속한 경우
높은 버전은 아이템 종류와 개수가 딕셔너리 메시지로 간다고 했을 때 낮은 버전은 아이템 종류만 메시지로 갈때
서버는 낮은 버전에서 온 메시지를 받아서 개수가 없으면 1로 처리하는 알고리즘을 쓸 수 있다. 


2.11 더 읽을 거리
FastAPI의 라우트 함수들이 일종의 RPC(원격 프로시저 호출, Remote Procedure Call)로 간주될 수 있습니다

    **RPC (Remote Procedure Call)**는 
    네트워크를 통해 다른 컴퓨터(혹은 같은 컴퓨터의 다른 프로세스)에 있는 함수를 호출하는 방법입니다. 
    클라이언트는 로컬 함수 호출처럼 보이는 방식으로 요청을 보내고, 서버는 해당 요청을 처리하여 결과를 반환합니다.

FastAPI 라우트 함수의 작동 방식
    클라이언트 요청: 클라이언트가 HTTP 요청을 보내면, FastAPI는 URL 경로와 HTTP 메서드(GET, POST, PUT, DELETE 등)에 매핑된 라우트 함수를 찾습니다.

    라우트 함수 호출: 요청이 적절한 라우트 함수에 도달하면, FastAPI는 해당 함수를 호출하고 요청 데이터를 함수의 인자로 전달합니다.

    응답 반환: 라우트 함수는 처리를 완료한 후 결과를 반환하고, FastAPI는 이 결과를 HTTP 응답으로 클라이언트에게 돌려줍니다.

    이 과정은 본질적으로 RPC와 매우 유사합니다. 클라이언트가 원격 서버의 함수를 호출하고, 그 결과를 받는 형태로 동작하기 때문입니다.





3장 소켓 프로그래밍

3.1 블로킹 소켓

3.2 네트워크 연결 및 송신

TCP는 일대일 통신만 허락한다. 다시 말해 TCP 소켓은 오직 1개의 엔드포인트하고만 통신할 수 있다. 따라서 상대방의 엔드포인트 뿐만 아니라
자신의 엔드포인트도 알아야 한다.
아래 송신쪽에서 bind에 자신의 포트를 넣는 이유는 그 때문이다

TCP 통신은
    송신쪽
        s = socket(TCP)
        s.bind(port)
        s.connect("11.22.33.44:5656") # 수신측의 엔드포인트를 넣고 연결될 때까지 블로킹. 연결이 되면 connect 함수는 리턴
        s.send("data") # send함수는 수신쪽으로 데이터를 전송하는 처리가 완료될때까지 블로킹이 걸리지 않고 즉시 리턴.
        s.close()

송신쪽에서 send 함수로 데이터를 보내면
데이터는 먼저 송신쪽의 송신버퍼(선입선출 큐)에 쌓인다.
송신버퍼가 가득 차기 전까지는 send함수는 즉시 리턴한다.
송신버퍼가 가득 찬 상태에서 send로 뭔가를 또 보내면 그때 블로킹이 발생한다.
운영체제가 송신버퍼에서 먼저 찬 데이터를 빼내면 그때 블로킹은 풀리고 send함수는 블로킹이 걸려 보내지 못한 데이터를 송신버퍼로 보내고 
즉시 리턴한다.
송신버퍼는 디폴트로 수천바이트를 담을 수 있기 때문에 어지간하면 바로 리턴한다.

송신쪽의 송신 버퍼는 선입선출 큐로 받은 데이터를 바로 내보낸다.

3.4 네트워크 연결받기 및 수신
    수신쪽
        s = socket(TCP)
        s.listen(5656)  # 수신측의 포트번호를 리슨소켓으로 즉시 리턴한다.
        s2.accept()     # 송신측으로부터 연결을 받을 때까지 블로킹, 연결되면 새로운 소켓 핸들값이 리턴
        while True:
            r = s2.recv()   # 새로운 소켓에서 데이터를 수신. 수신할 데이터가 올때까지 블로킹. 데이터가 오면 recv()는 바로 리턴
                                  # 연결 끊어짐 등 오류가 발생하면 -1 리턴
            if r.length == 0: # TCP는 스트림이므로 0바이트 데이터가 오게 되면 더이상 수신시도를 하지 않고 연결을 끝냄. 
                break
            print(r.data)
        s.close() 

수신쪽의 수신버퍼는 운영체제가 송신쪽으로 받은 데이터를 수신버퍼에 푸시. 그러면 사용자는 수신버퍼에 있는데이터를 팝 (송신과 반대)

따라서 수신버퍼가 비어있으면 recv()는 블로킹이 걸린다.

3.5 수신버퍼가 가득 차면 발생하는 현상
반대로 수신버퍼가 가득차있는 경우 (수신 함수가 수신버퍼에서 데이터를 꺼내는 속도 < 운영체제가 수신버퍼의 데이터를 채우는 속도)
송신쪽의 send() 함수가 블로킹된다. 이상태에서는 연결만 살아 있고 오가는 통신은 없다

다시 말하면 송신함수로 송신버퍼에 데이터를 쌓는 속도보다, 수신 함수로 수신버퍼에서 데이터를 꺼내는 속도가 느리다고 해서 연결이 끊어지지 않는다
블로킹될 뿐


UDP의 경우

UDP 통신은
    송신쪽
        s = socket(UDP)
        s.bind(port)
        s.sendTO("11.22.33.44:5656", "data")
        s.close()
    수신쪽
        s = socket(UDP)
        s.bind(5656)
        r = s.recvfrom()
        print(r.data)
        s.close() 


UDP 소켓은 데이터그램이 최소 1개 도착해 있으면 즉시 리턴, 아니면 도착할때까지 블로킹

수신 버퍼가 가득 찬 경우, 새로 온 데이터그램은 그냥 버려진다. 즉 송신쪽의 sendTO에서 블로킹이 걸리지 않는다. 


3.6 논블록 소켓

from fastapi import FastAPI, WebSocket
from typing import List

app = FastAPI()

clients: List[WebSocket] = []

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    clients.append(websocket)
    try:
        while True:
            data = await websocket.receive_text()
            for client in clients:
                await client.send_text(data)
    except:
        clients.remove(websocket)














fastapi서버에서 클라이언트에게 직접 요청을 보내려면 
클라이언트의 엔드포인트를 알고 있어야 겠지? 그걸 아는 방법은
먼저 서버가 fastapi서버로 클라이언트가 접속할수 있는 url을 먼저 클라이언트에게 주고 
리슨 소켓을 열어서 접속을 기다리면

클라이언트는 해당 주소로 연결을 하고
자신의 엔드포인트를 서버에 알려줘
그리고 서버가 요청을 다시 줄때까지 리슨 소켓을 열어놔.

클라이언트와 서버는 각각 서로가 준 엔드포인트를 저장하고
이제 서버는 클라이언트에게 명령을 하고 싶을 때 해당 엔드포인트로 요청을 보내

이 연결은 둘 중 하나가 닫을 때까지 끊어지지 않고
서로의 요청을 계속 기다리는 함수가 실행중인 것으로 구현할수 있어.

그러면 클라이언트들과 딜러가 최초 연결될 때 
딜러는 클라이언트 수만큼 웹소켓을 만들어서 게임이 끝날때까지 연결을 유지한다?



















4장 게임서버와 클라이언트

게임 루프 : 
    입력 받기 - 게임 로직 처리 - 렌더링

입력 받기 : 
    키보드, 마우스, 터치스크린, 마이크, 카메라 등으로 컴퓨터가 정보를 획득하는 과정

게임 로직 처리 : 
    게임 정보를 담고 있는 상태인 세션은 보통 1초에 60번 상태변화를 한다. <<<<<<<<<<<<<<<<<<<<<<<<
    상태 변화를 하는 과정을 게임 로직
    게임 로직 처리 과정 중에는 
        게임 플레이 판정, 
        가령 어느 플레이어가 어느 캐릭터에 대미지를 주었는지 
        혹은 캐릭터가 어느 몬스터 캐릭터에 대미즈를 받았는지 등을 계산한다.
    렌더링 : 변화된 상태를 화면에 표현


대부분 온라인 게임에서는 서버에서 게임로직을 처리하는 역할 일부를 떼어 내 클라이언트로 옮긴다

    클라이언트 : 입력받기 - 게임 로직 - 렌더링
    서버 : 게임로직

클라이언트와 서버의 상호작용은 크게 네가지로 구별된다.
    1. 연결 : 클에서 서버에 연결요청, 서버는 수락 (TCP 연결)
    2. 클 요청 - 서버 응답 
    3. 능동적 통보 : 클에서 서버로 요청보내지 않아도, 서버가 클에게 일방적으로 통보
    4. 연결 해제

능동적 통보의 예 : 게임 서버는 세션을 하나 이상 가지고 있는 상태기계 state machine 이다. 
    이 세션의 상태는 시간이 지나면서 변화한다. 이변화를 클에게 일정시간마다 통보 <<<<<<<<<<<<<<<<<<<<<<<<


서버가 하는일
    1. 여러 사용자와 상호작용
    2. 클에서 해킹당하면 안 되는 처리
    3. 플레이어의 상태 보관
        온라인 게임에서 플레이어 정보는 클에 저장하지 않는다.

    클에서 플레이어의 입력을 받으면 
    클은 플레이어의 입력을 서버에 전달한다.
    서버에서는 세션의 모든 캐릭터 상태를 1/60초마다 변화시켜서 그결과를 클에게 보내준다. <<<<<<<<<<<<<<<<<<<<<<<<
    그럼 거꾸로 모든 클에서는 자신의 상태를 1/60초마다 서버에 전송? <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<


개발과정에서 안정성 확보
    1. 치밀한 개발과 유닛테스트
        모든 함수 호출의 반환값을 반드시 체크하는 루틴
        개발된 프로그램의 각 부분은 반드시 자동화된 자가검증, 유닛테스트를 만들어야 한다
    
    2. 80:20 법칙
        모든 프로그램 성능의 80%는 20%의 소스코드에서 나타난다(파레토 법칙)
        성능에 지대한 영향을 주는 일부분의 소스코드에서만 프로그램 구조가 복잡해 지더라도 성능을 최적화해서 개발하고 <<<<<<<<<<<<<<<<<<<<<<<<
        나머지 대부분은 성능보다 유지보수하기 쉬운 단순한 구조로 개발한다
    
    3. 봇 테스트(더미 클라이언트 테스트, 스트레스 테스트)
        서버를 띄우고 대량의 더미 클라이언트를 실행한다.
        더미 클라이언트는 입력처리와 렌더링과정이 생략되어 있고 미리 프로그래밍된 행동을 반복한다. 
        이를 대량으로 서버에 접속시킨다. 
        그리고 서버에서는 성능지표를 켜서 서버에 걸리는 과부하나 이상행동 현상을 관찰하고 
        문제점 발견되면 테스트 중단, 문제를 해결, 더 이상 문제가 없을 때까지 반복한다.
    4. 클로즈 베타 테스트
    5. 오픈 베타 테스트
    6. 출시


서버 안전장치
    1. 서버가 중지할 경우 서버활동을 감시하던 프로그램이 서버 프로그램을 다시 실행시키게 하는 방법
    2. 서버가 비정상 종료를 하는 마지막 순간의 프로세스 상태, 
    crash dump를 파일로 남기거나 서버가 최근에 받았던 메시지 종류를 파일로 남기는 방법
    3. 같은 역할을 하는 서벌을 두 대 이상둬서 앞의 서버가 죽으면 뒤의 서버가 이어받아 서버작동 유지.

온프레미스 서버
    데이터센터에 직접 서버 하드웨어와 운영체제를 설치해서 관리하는 걸 
    자체 서버 혹은 on premise 서버 라고 한다.
    
   (on-premise)
    서버 소프트웨어
    운영체제
    하드웨어

클라우드 서버
    이 대안으로 클라우드 서버가 있다.
    클라우드 서버는 서버 컴퓨터 한대에 여러 운영체제를 가상머신으로 구동한다

    (클라우드)
    서버 소프트웨어
    운영체제
    가상머신
    하이퍼바이저소프트웨어
    하드웨어

계층에 따른 클라우드 서버 종류

IaaS (Infrastructure as a Service) AWS EC2, Azure Vitual machine
    애플리케이션 (직접 설치 및 실행)
    서버프레임워크 (직접 설치 및 실행)
    운영체제 (직접 설치)
    하이퍼바이저
    하드웨어

PaaS (Platform as a Service) AWS Lambda, Azure Functions
    애플리케이션 (직접 설치 및 실행)
    서버프레임워크 
    운영체제 
    하이퍼바이저
    하드웨어


SaaS (Sofrware as a Service) AWS cognito, Azure Marketplace, Google Analytucs
    애플리케이션 (특화된 기능까지 다 제공. 그냥 가져다 쓰기만 하면 되는.)
    서버프레임워크 
    운영체제 
    하이퍼바이저
    하드웨어


5장

UML : 
    프로그램 구조 명세를 표현하는 플로차트

    UML 시퀀스 다이어그램 : 
        객체간 메시징 흐름을 일목요연하게 표현할 용도로 사용
        액티비티 다이어그램: 좀더 자세한 플로우 차트


모든 역할을 서버에서 하기(옛날 방식)

    클 : 사용자 입력 받기, 서버에서 보내주는 글자, 이미지, 동영상을 받아 화면 출력만
    서 : 게임 로직 연산, 화면 렌더링, 화면 송출

렌더링만 클라이언트에서 하기 (서버의 월드 상태를 클에 동기화하는 방식)
    서 : 렌더링을 위한 최소정보인 게임 월드 상태만 클에게 보냄. 월드 상태 연산은 서버에서.
    클 : 렌더링 수행.
    서버와 클라이언트의 월드상태(씬)을 동일하게 유지. 즉 동기화

지속성 이벤트 : 
    씬의 상태에 영구적인 변화를 가하는 것 (캐릭터 이동, 사라짐 등)
    즉, 클이 계속 렌더링 해줘야 하는 것 

단발성 이벤트 : 
    씬의 변화에 영향을 잠깐 주고 사라지는 것 (수류탄 폭발 연출)
    즉, 클이 일정 시간 동안에만 렌더링 해주면 되는 것

    단발성 이벤트는 서-클간 그 시작과 끝 사이의 모든 과정을 통신할 필요 없다. 
    시작과 끝만 하면 됨

렌더링만 클라이언트에서 하기 방식이 원활하게 작동하려면
    1. 서버에서는 1/60초마다 월드 상태를 업데이트한다 <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
    2. 서버는 1/60초마다 월드상태의 변화를 클에게 보낸다
    3. 클은 이를 지체없이 받는다
    4. 클은 받은것을 자기의 월드상태에 반영하고 다음 렌더링 프레임에서 이를 그린다

    이 과정이 원활하게 작동하려면 서와 클 사이에 latency가 1/60초보다 훨씬 낮아야 하고 그 레이턴시는 항상 균일해야 한다.
        이런 환경은 로컬 네트워크 LAN 이 아닌 이상 쉽지 않다.
        또 서버에 접속한 클이 많아질수록 점점 어려워진다.
       
            예를 들어 FPS에서는 플레이어가 저격총을 쏠 때 이 저격총에 대해 0.01초 이내에 처리를 해야 한다.
            플1 > 클1 > 서 
                플1이 플2에게 저격총을 쏘는 순간 클1은 서버에 플1이 플2에게 저격총을 쐈다는 메시지를 보내고  
            서 > 클2 > 플2
                서버는 이를 받아서 클2에 클1이 쏜 헤드샷으로 죽었다는 메시지를 보내면
                클2는 이 메시지를 받고 플2가 죽는 모습으로 바꾼다
                (한국에서는 보통 500 km이내에서는 1밀리초(0.001초) 안에 도달한다.
                    0.5밀리초(0.0005초) 안에 도착하고 서버처리 시간이 0.1밀리초(0.0001초)라고 가정하면
                    총 걸리는 시간은 0.5 + 0.1 + 0.1 = 0.7 밀리초(0.0007초)다.

                동시접속자 수가 5000명 정도라고 해보자.
                    FPS에서는 플의 이동과 발포를 처리하는데 메시지를 평균 초당 20회 서버에 전송한다.
                    서버가 1초에 받아서 처리하는 메시지 수는 10만개다.
                    서버가 메시지 1개를 처리하는데 0.1초(0.0001초)가 걸린다면 
                    서가 초당 처리할 수 있는 최대 메시지는 1만 개임을 의미한다.)
       
        해법 : 1. 게임서버의 성능을 높이거나, 
                게임 서버의 성능을 높이는 방법
                    1 프로그램 코드 최적화, 알고리즘 최적화
                    2 코드 프로파일링으로 어떤 함수가 처리 시간을 많이 차지하는지 발견한후 최적화하거나 
                        최적화가 불가능하면 다른 컴퓨터에서 실행하게 한다.
                    3 네트워크 프로토콜 최적화 (메시지 양 줄이기-메시지 압축/양자화, 메시지 교환횟수 줄이기
                    4 지리적으로 가까운 서버에 클이 모이도록
                 5 P2P
              2. 추측항법 234p, 
              3. 레이턴시 마스킹 237p. 247p까지


온라인 게임을 개발할 때는 컴간에 어떤 대화가 오가는지 순서를 미리 문서로 작성해 놓는것이 좋다.
이과정을 건너뛰고 마구잡이로 코딩부터 들어가면 길을 잃기 쉽다.

로그인 과정
    1. 클 : 로그온 요청 메시지 서버로 전송
    2. 서버 : DB에서 해당 유저의 ID와 PW 식별
    3. 서버 : 로그온 처리결과 클에게 통보

게임룸 생성 과정
    1. 클1 : 서버에 게임룸 생성 요청
    2. 서버 : 게임룸 생성 성공여부 클에게 알림
    3. 서버 : 다른 클라이언트 들에게 게임룸 생성 사실 알림
    4. 클2 : 서버에 게임룸 참여 요청
    5. 서버 : 클2에게 게임룸 참여 성공여부 알림
    6. 서버 : 클1에게 누군가 게임룸에 들어옴 알림
    7. 클1 : 서버에 게임시작 요청
    8. 서버 : 클1, 클2에게 게임 시작 알림
    
    이게 되려면 서버에는 
    게임룸 목록
    각 게임룸에 들어가 있는 플레이어 목록
    게임플레이 중인 방의 상태 데이터
    등을 갖고 있어야 한다.
    
게임로직을 개발하는 과정에서 서버와 클이 어떤 대화를 니눠야 할지는 원하는대로 정하면 되는데 
거기에 적용되는 기본 규칙

클이 서버로 요청
서버는 요청 결과 판단
요청 결과에 영향을 받는 다른 클이 서버에 있으면 그 클에도 통보


보안 
암호키로 암호화와 복호화를 하는 알고리즘을 대칭 키 알고리즘 이라고 한다. 주로 쓰이는 알고리즘은 AES
암호키1(public key) 암호키2(private key)를 쓰는 알고리즘을 비대칭 키 알고리즘이라고 한다. 주로 RSA 알고리즘을 쓴다.

핵심
1. text를 암호키로 암호화 한다.
2. 암호키를 3개 만들어 하나(2)는 서버에만 보관하고 다른 하나(3)는 클에 만들게 하고, 다른 하나(1)는 서버에서 클에게 알려준다.
3. 암호키1(public key)로 암호화된 암호문은 암호키2(private key)로 복호화된다.
4. 암호키3(symmetric key, session key)은 암호키1로 암호화된다.
5. 암호키3(symmetric key, session key)은 ID와 PW를 암호화한다.

서버는 암호키 1을 클에게 준다.
클은, 자신이 만든 암호키3을 암호키1로 암호화 해서 서버에 보내고
다시 클은, 자신이 만든 암호키3으로 ID랑 비번을 암호화해서 서버에 보낸다.
서버에는 암호키2가 있기 때문에
클이 보낸 암호키3을 알아낼 수 있다.

서버 : 암호키1(public key)을 클에게 보냄 (해커가 암호키1을 중간에 훔침)

클 : 암호키3(symmetric key, session key)를 만들어 이를 암호키1로 암호화 해서 서버에 보냄 (해커가 암호키1로 암호화된 암호키를 중간에 훔침)

서버 : 클이 보낸 암호문을 암호키2(private key)로 복호화 해서 클이 만든 암호키를 얻음 (해커는 암호키2가 없으므로 위에서 훔친 암호문을 복호화할 수 없음)

클 : ID와 비번을 암호키3(symmetric key)로 암호화하여 서버에 보냄 (해커가 암호문을 훔침. 클이 만든 암호키로 복호화할 수 있는데, 클이 만든 암호키를 알 수 없음, 결과적으로 해커는 암호키2가 있어야 한다.)

서버 : 클이 만든 암호키3(symmetric key)로, 클이 보낸 암호문을 복호화해서 ID와 비번을 확인









